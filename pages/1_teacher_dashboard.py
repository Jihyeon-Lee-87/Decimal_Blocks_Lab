# -*- coding: utf-8 -*-
# êµì‚¬ ëŒ€ì‹œë³´ë“œ (KPIs + íƒ­ ì‹œê°í™” 5ì¢…)
# - ì ‘ê·¼ ì œì–´: st.session_state["teacher_ok"] í•„ìš”
# - í•„í„°: ë‚ ì§œ / í•™ê¸‰
# - KPIs: ì´ ì œì¶œ, í‰ê·  ìê¸°í‰ê°€, ì „ì²´ ì •ë‹µë¥ , ìµœê·¼ ì œì¶œ ì‹œê°
# - íƒ­:
#   1) ì „ì²´ ì •ë‹µë¥ (ë„ë„›) + ë¶„í¬
#   2) í•™ê¸‰ë³„ ì •ë‹µë¥ (ë§‰ëŒ€)
#   3) í•™ê¸‰ë³„ ì œì¶œ ìˆ˜(ë§‰ëŒ€)
#   4) ë‚ ì§œë³„ ì œì¶œ ì¶”ì´(ì„ )
#   5) í•™ìƒ ë‹µë³€ í‚¤ì›Œë“œ(ìƒìœ„ 30, ê°€ë²¼ìš´ í† í¬ë‚˜ì´ì €)

import re
import sqlite3
from pathlib import Path
from contextlib import closing
from datetime import date, timedelta

import pandas as pd
import streamlit as st

st.set_page_config(page_title="êµì‚¬ ëŒ€ì‹œë³´ë“œ", page_icon="ğŸ“Š", layout="wide")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì ‘ê·¼ ì œì–´ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if not st.session_state.get("teacher_ok", False):
    st.error("êµì‚¬ ì „ìš© í˜ì´ì§€ì…ë‹ˆë‹¤. ë©”ì¸ í™”ë©´ ì‚¬ì´ë“œë°”ì—ì„œ 'êµì‚¬' ì„ íƒ í›„ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    st.stop()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ìë™ ìƒˆë¡œê³ ì¹¨(ì„ íƒ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
try:
    from streamlit_autorefresh import st_autorefresh
    if st.toggle("30ì´ˆ ìë™ ìƒˆë¡œê³ ì¹¨", value=False, key="teacher_autorefresh"):
        st_autorefresh(interval=30_000, key="teacher_dash_autorefresh_tabs")
except Exception:
    st.caption("â± `streamlit-autorefresh` ë¯¸ì„¤ì¹˜ ìƒíƒœ(ì„ íƒ). requirements.txtì— `streamlit-autorefresh>=0.0.2` ì¶”ê°€ ì‹œ ì‚¬ìš© ê°€ëŠ¥.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ DB ìœ í‹¸ (/mount/data ìš°ì„ ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _writable_data_dir() -> Path:
    for p in [Path("/mount/data"), Path.cwd() / ".data"]:
        try:
            p.mkdir(parents=True, exist_ok=True)
            t = p / "_wtest"
            with open(t, "w") as f: f.write("ok")
            t.unlink(missing_ok=True)
            return p
        except Exception:
            continue
    Path.cwd().mkdir(parents=True, exist_ok=True)
    return Path.cwd()

DATA_DIR = _writable_data_dir()
DB_PATH  = str(DATA_DIR / "submissions.db")

@st.cache_resource
def get_conn():
    conn = sqlite3.connect(DB_PATH, check_same_thread=False)
    with conn:
        conn.execute("""
            CREATE TABLE IF NOT EXISTS submissions(
              id INTEGER PRIMARY KEY AUTOINCREMENT,
              timestamp TEXT,
              class TEXT,
              nickname TEXT,
              quest TEXT,
              rubric_1 INTEGER,
              rubric_2 INTEGER,
              rubric_3 INTEGER,
              rubric_total INTEGER,
              guess_mode TEXT,
              guess_value TEXT,
              guess_correct INTEGER,
              correct_answer TEXT
            )
        """)
        conn.execute("PRAGMA journal_mode=WAL;")
        conn.execute("PRAGMA synchronous=NORMAL;")
    return conn

def fetch_all() -> pd.DataFrame:
    conn = get_conn()
    with closing(conn.cursor()) as cur:
        cur.execute("""
          SELECT timestamp, class, nickname, quest,
                 rubric_1, rubric_2, rubric_3, rubric_total,
                 guess_mode, guess_value, guess_correct, correct_answer
          FROM submissions
          ORDER BY datetime(timestamp) DESC
        """)
        cols = ["timestamp","class","nickname","quest",
                "rubric_1","rubric_2","rubric_3","rubric_total",
                "guess_mode","guess_value","guess_correct","correct_answer"]
        rows = cur.fetchall()
    return pd.DataFrame(rows, columns=cols)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ìƒë‹¨ ì œëª©/ë²„íŠ¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.title("ğŸ“Š êµì‚¬ ëŒ€ì‹œë³´ë“œ")
st.caption("ëª¨ë“  ì‹œê°„ì€ KST(Asia/Seoul) ê¸°ì¤€ìœ¼ë¡œ ì €ì¥Â·í‘œì‹œë©ë‹ˆë‹¤.")
if st.button("ğŸ”„ ìƒˆë¡œê³ ì¹¨"):
    st.rerun()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë°ì´í„° ë¡œë”© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
df = fetch_all()
if df.empty:
    st.warning("ì•„ì§ ì œì¶œì´ ì—†ìŠµë‹ˆë‹¤. í•™ìƒ í™”ë©´ì—ì„œ ì œì¶œ í›„ ë‹¤ì‹œ ìƒˆë¡œê³ ì¹¨í•˜ì„¸ìš”.")
    st.stop()

# ì „ì²˜ë¦¬
df["dt"] = pd.to_datetime(df["timestamp"], errors="coerce")
df["date"] = df["dt"].dt.date
df["rubric_total"] = pd.to_numeric(df["rubric_total"], errors="coerce")
df["guess_correct_num"] = pd.to_numeric(df["guess_correct"], errors="coerce")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í•„í„° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
fltL, fltM, fltR = st.columns([2,2,3])
with fltL:
    max_day = df["date"].max()
    min_day = df["date"].min()
    default_start = max(min_day, (max_day or date.today()) - timedelta(days=14))
    start_day = st.date_input("ì‹œì‘ì¼", value=default_start,
                              min_value=min_day, max_value=max_day or date.today())
with fltM:
    end_day = st.date_input("ì¢…ë£Œì¼", value=max_day or date.today(),
                            min_value=min_day, max_value=max_day or date.today())
with fltR:
    class_options = ["4-ì‚¬ë‘","4-ê¸°ì¨","4-ë³´ëŒ","4-í–‰ë³µ","ê¸°íƒ€"]
    sel_classes = st.multiselect("í•™ê¸‰(ë³µìˆ˜ ì„ íƒ)", class_options, default=class_options)

if start_day > end_day:
    st.error("ì‹œì‘ì¼ì´ ì¢…ë£Œì¼ë³´ë‹¤ ëŠ¦ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

mask = (df["date"] >= start_day) & (df["date"] <= end_day) & (df["class"].isin(sel_classes))
fdf = df.loc[mask].copy()
if fdf.empty:
    st.info("ì„ íƒí•œ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ì œì¶œì´ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ì¡°ì •í•´ ì£¼ì„¸ìš”.")
    st.stop()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ KPI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
K1, K2, K3, K4 = st.columns(4)
with K1:
    st.metric("ì´ ì œì¶œ", len(fdf))
with K2:
    st.metric("í‰ê·  ìê¸°í‰ê°€ ì´ì ", round(fdf["rubric_total"].dropna().astype(int).mean(), 2))
with K3:
    if fdf["guess_correct_num"].notna().any():
        acc = fdf["guess_correct_num"].fillna(0).astype(int).mean() * 100
        st.metric("ì „ì²´ ì •ë‹µë¥ ", f"{acc:.0f}%")
    else:
        st.metric("ì „ì²´ ì •ë‹µë¥ ", "â€”")
with K4:
    st.metric("ìµœê·¼ ì œì¶œ ì‹œê°", str(fdf.sort_values("dt").iloc[-1]["timestamp"]))

st.divider()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ íƒ­ 5ì¢… â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
tabs = st.tabs(["ì „ì²´ ì •ë‹µë¥ ", "í•™ê¸‰ë³„ ì •ë‹µë¥ ", "í•™ê¸‰ë³„ ì œì¶œ ìˆ˜", "ë‚ ì§œë³„ ì œì¶œ ì¶”ì´", "í•™ìƒ ë‹µë³€ í‚¤ì›Œë“œ"])

def altair_available() -> bool:
    try:
        import altair as alt  # noqa
        return True
    except Exception:
        return False

# ê³µí†µ íŒŒìƒ ë°ì´í„°
correct_counts = fdf["guess_correct_num"].map({1:"ì •ë‹µ",0:"ì˜¤ë‹µ"}).value_counts().rename_axis("ì •ë‹µì—¬ë¶€").reset_index(name="ëª…")
by_class_acc = (fdf.groupby("class")["guess_correct_num"]
                .mean().mul(100).round(1).rename("ì •ë‹µë¥ (%)").reset_index())
by_class_acc = by_class_acc.rename(columns={"class": "í•™ê¸‰"})
by_class_cnt = fdf["class"].value_counts().rename_axis("í•™ê¸‰").reset_index(name="ì œì¶œ ìˆ˜")
by_day = (fdf.groupby("date").size().rename("ì œì¶œ ìˆ˜").reset_index().sort_values("date"))
hist = (fdf["rubric_total"].dropna().astype(int)
        .value_counts().sort_index().rename_axis("ì´ì (0â€“6)").reset_index(name="ëª…"))

# 1) ì „ì²´ ì •ë‹µë¥ 
with tabs[0]:
    st.subheader("ì „ì²´ ì •ë‹µë¥ ")
    if correct_counts.empty:
        st.info("ì •ë‹µ/ì˜¤ë‹µ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        if altair_available():
            import altair as alt
            # ë„ë„›
            donut = alt.Chart(correct_counts).mark_arc(innerRadius=60).encode(
                theta="ëª…:Q",
                color=alt.Color("ì •ë‹µì—¬ë¶€:N", sort=["ì •ë‹µ","ì˜¤ë‹µ"]),
                tooltip=["ì •ë‹µì—¬ë¶€","ëª…"]
            ).properties(height=320)
            st.altair_chart(donut, use_container_width=True)
        else:
            st.bar_chart(correct_counts.set_index("ì •ë‹µì—¬ë¶€"))
    st.caption("ì™¼ìª½ KPIì—ë„ ì „ì²´ ì •ë‹µë¥ ì´ í‘œì‹œë©ë‹ˆë‹¤.")

# 2) í•™ê¸‰ë³„ ì •ë‹µë¥ 
with tabs[1]:
    st.subheader("í•™ê¸‰ë³„ ì •ë‹µë¥ ")
    if by_class_acc.empty:
        st.info("í•™ê¸‰ë³„ ì •ë‹µë¥  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        if altair_available():
            import altair as alt
            chart = alt.Chart(by_class_acc).mark_bar().encode(
                x=alt.X("í•™ê¸‰:N", sort="-y"),
                y=alt.Y("ì •ë‹µë¥ (%):Q"),
                tooltip=["í•™ê¸‰","ì •ë‹µë¥ (%)"]
            ).properties(height=360)
            st.altair_chart(chart, use_container_width=True)
        else:
            st.bar_chart(by_class_acc.set_index("í•™ê¸‰"))

# 3) í•™ê¸‰ë³„ ì œì¶œ ìˆ˜
with tabs[2]:
    st.subheader("í•™ê¸‰ë³„ ì œì¶œ ìˆ˜")
    if by_class_cnt.empty:
        st.info("í•™ê¸‰ë³„ ì œì¶œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        if altair_available():
            import altair as alt
            chart = alt.Chart(by_class_cnt).mark_bar().encode(
                y=alt.Y("í•™ê¸‰:N", sort="-x"),
                x=alt.X("ì œì¶œ ìˆ˜:Q"),
                tooltip=["í•™ê¸‰","ì œì¶œ ìˆ˜"]
            ).properties(height=360)
            st.altair_chart(chart, use_container_width=True)
        else:
            st.bar_chart(by_class_cnt.set_index("í•™ê¸‰"))

# 4) ë‚ ì§œë³„ ì œì¶œ ì¶”ì´
with tabs[3]:
    st.subheader("ë‚ ì§œë³„ ì œì¶œ ì¶”ì´")
    if by_day.empty:
        st.info("ë‚ ì§œë³„ ì œì¶œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        if altair_available():
            import altair as alt
            chart = alt.Chart(by_day).mark_line(point=True).encode(
                x=alt.X("date:T", title="ë‚ ì§œ"),
                y=alt.Y("ì œì¶œ ìˆ˜:Q"),
                tooltip=["date:T","ì œì¶œ ìˆ˜:Q"]
            ).properties(height=360)
            st.altair_chart(chart, use_container_width=True)
        else:
            st.line_chart(by_day.set_index("date"))

# 5) í•™ìƒ ë‹µë³€ í‚¤ì›Œë“œ
with tabs[4]:
    st.subheader("í•™ìƒ ë‹µë³€ í‚¤ì›Œë“œ(ìƒìœ„ 30)")
    # ì•„ì£¼ ê°€ë²¼ìš´ í† í¬ë‚˜ì´ì €(í•œ/ì˜/ìˆ«ì ì—°ì† í† í° ì¶”ì¶œ)
    texts = fdf["quest"].dropna().astype(str)
    if texts.empty:
        st.info("ë¬¸í•­/ê³¼ì œ(í•™ìƒ ììœ  ì…ë ¥)ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        tokens = []
        hangul_re = re.compile(r"[ê°€-í£A-Za-z0-9]+")
        stop = set([
            "ê·¸ë¦¬ê³ ","ê·¸ë˜ì„œ","í•˜ì§€ë§Œ","í˜¹ì€","ë˜ëŠ”","ë˜","ì¦‰","ì´ê±´","ì €ëŠ”","ì œê°€","ìš°ë¦¬ëŠ”","ë„ˆë¬´",
            "ì •ë‹µ","ì˜¤ë‹µ","ë°›ì•„ì˜¬ë¦¼","ë°›ì•„ë‚´ë¦¼","í•©","ì°¨","ë¬¸ì œ","ê³¼ì œ","ì„¤ëª…","ìœ¼ë¡œ","ì—ì„œ","í•˜ë‹¤","í–ˆë‹¤",
            "ì…ë‹ˆë‹¤","ì˜ˆ","ì•„ë‹ˆì˜¤","ì˜ˆì‹œ","ê°™ì€","ì´ë²ˆ","ì˜¤ëŠ˜","í•©ë‹ˆë‹¤","í–ˆë˜","ìˆëŠ”","ì—†ëŠ”","ì–´ë–»ê²Œ","ì™œ",
            "ìˆ˜","ìˆ«ì","ìë¦¬","ì†Œìˆ˜","ì²«ì§¸","ë‘˜ì§¸","ì…‹ì§¸","ìë¦¬ìˆ˜","ê³„ì‚°","ë¹Œë¦¬ë‹¤","ë”í•˜ë‹¤","ë¹¼ë‹¤"
        ])
        for line in texts:
            for tok in hangul_re.findall(line.lower()):
                # ë„ˆë¬´ ì§§ì€ í† í°/ìˆ«ìë§Œ í† í° ì œì™¸
                if len(tok) < 2: 
                    continue
                if tok.isdigit():
                    continue
                if tok in stop:
                    continue
                tokens.append(tok)

        if not tokens:
            st.info("ìœ ì˜ë¯¸í•œ í‚¤ì›Œë“œë¥¼ ì°¾ê¸° ì–´ë ¤ì› ìŠµë‹ˆë‹¤.")
        else:
            freq = pd.Series(tokens).value_counts().head(30).rename_axis("í‚¤ì›Œë“œ").reset_index(name="ë¹ˆë„")
            if altair_available():
                import altair as alt
                chart = alt.Chart(freq).mark_bar().encode(
                    y=alt.Y("í‚¤ì›Œë“œ:N", sort="-x"),
                    x=alt.X("ë¹ˆë„:Q"),
                    tooltip=["í‚¤ì›Œë“œ","ë¹ˆë„"]
                ).properties(height=480)
                st.altair_chart(chart, use_container_width=True)
            else:
                st.bar_chart(freq.set_index("í‚¤ì›Œë“œ"))
            with st.expander("í‘œë¡œ ë³´ê¸°"):
                st.dataframe(freq, use_container_width=True, height=420)

st.divider()
csv = fdf.drop(columns=["dt"]).to_csv(index=False).encode("utf-8-sig")
st.download_button("CSV ë‹¤ìš´ë¡œë“œ(í•„í„° ì ìš©)", csv, file_name="submissions_filtered.csv", mime="text/csv")














