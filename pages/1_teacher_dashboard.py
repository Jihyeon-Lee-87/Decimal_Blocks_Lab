# -*- coding: utf-8 -*-
# êµì‚¬ ëŒ€ì‹œë³´ë“œ(ê°•í™”íŒ)
# - KST ê¸°ì¤€ íƒ€ì„ìŠ¤íƒ¬í”„ í‘œì‹œ
# - ë‚ ì§œ/í•™ê¸‰ í•„í„°
# - KPI + ìµœê·¼ ì œì¶œ/í•™ê¸‰ë³„ ì œì¶œ í‘œ
# - íƒ­ 5ê°œ: ì •ë‹µì—¬ë¶€ ë¹„ìœ¨, ìê¸°í‰ê°€ ì´ì  ë¶„í¬, í•™ê¸‰ë³„ ì •ë‹µë¥ , í•™ê¸‰ë³„ ì œì¶œ ìˆ˜, ë‚ ì§œë³„ ì œì¶œ ì¶”ì´
# - NEW: ììœ ì‘ë‹µ í‚¤ì›Œë“œ(ìƒìœ„ ë¹ˆë„) íƒ­ ì¶”ê°€
# - ìë™ ìƒˆë¡œê³ ì¹¨ í† ê¸€, ìˆ˜ë™ ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼

import re
import sqlite3
from pathlib import Path
from contextlib import closing
from datetime import date, timedelta

import pandas as pd
import streamlit as st

st.set_page_config(page_title="êµì‚¬ ëŒ€ì‹œë³´ë“œ", page_icon="ğŸ“Š", layout="wide")

# --- ì ‘ê·¼ ì œì–´ ---
if not st.session_state.get("teacher_ok", False):
    st.error("êµì‚¬ ì „ìš© í˜ì´ì§€ì…ë‹ˆë‹¤. ë©”ì¸ í™”ë©´ ì‚¬ì´ë“œë°”ì—ì„œ 'êµì‚¬' ì„ íƒ í›„ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    st.stop()

# --- 30ì´ˆ ìë™ ìƒˆë¡œê³ ì¹¨ í† ê¸€ ---
try:
    from streamlit_autorefresh import st_autorefresh
    if st.toggle("30ì´ˆ ìë™ ìƒˆë¡œê³ ì¹¨", value=False, key="teacher_autorefresh"):
        st_autorefresh(interval=30_000, key="teacher_dash_autorefresh_tabs")
except Exception:
    st.caption("â± `streamlit-autorefresh` ë¯¸ì„¤ì¹˜ ìƒíƒœ(ì„ íƒ ì‚¬í•­). requirements.txtì— ì¶”ê°€í•˜ë©´ ìë™ ìƒˆë¡œê³ ì¹¨ ì‚¬ìš© ê°€ëŠ¥.")

# --- DB ìœ í‹¸ (ë£¨íŠ¸/submissions.db ê³ ì •) ---
ROOT_DIR = Path(__file__).resolve().parents[1]
DB_PATH  = str(ROOT_DIR / "submissions.db")

@st.cache_resource
def get_conn():
    conn = sqlite3.connect(DB_PATH, check_same_thread=False)
    with conn:
        conn.execute("""
            CREATE TABLE IF NOT EXISTS submissions(
              id INTEGER PRIMARY KEY AUTOINCREMENT,
              timestamp TEXT,
              class TEXT,
              nickname TEXT,
              quest TEXT,
              rubric_1 INTEGER,
              rubric_2 INTEGER,
              rubric_3 INTEGER,
              rubric_total INTEGER,
              guess_mode TEXT,
              guess_value TEXT,
              guess_correct INTEGER,
              correct_answer TEXT
            )
        """)
    return conn

def fetch_all() -> pd.DataFrame:
    conn = get_conn()
    with closing(conn.cursor()) as cur:
        cur.execute("""
          SELECT timestamp, class, nickname, quest,
                 rubric_1, rubric_2, rubric_3, rubric_total,
                 guess_mode, guess_value, guess_correct, correct_answer
          FROM submissions
          ORDER BY datetime(timestamp) DESC
        """)
        cols = ["timestamp","class","nickname","quest",
                "rubric_1","rubric_2","rubric_3","rubric_total",
                "guess_mode","guess_value","guess_correct","correct_answer"]
        rows = cur.fetchall()
    return pd.DataFrame(rows, columns=cols)

def altair_available() -> bool:
    try:
        import altair as alt  # noqa
        return True
    except Exception:
        return False

st.title("ğŸ“Š êµì‚¬ ëŒ€ì‹œë³´ë“œ")
st.caption("ëª¨ë“  ì‹œê°„ì€ KST(Asia/Seoul) ê¸°ì¤€ìœ¼ë¡œ ì €ì¥Â·í‘œì‹œë©ë‹ˆë‹¤.")

# ìˆ˜ë™ ìƒˆë¡œê³ ì¹¨
if st.button("ğŸ”„ ìƒˆë¡œê³ ì¹¨"):
    st.rerun()

# ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬
df = fetch_all()
if df.empty:
    st.warning("ì•„ì§ ì œì¶œì´ ì—†ìŠµë‹ˆë‹¤. í•™ìƒ í™”ë©´ì—ì„œ ì œì¶œ í›„ ë‹¤ì‹œ ìƒˆë¡œê³ ì¹¨í•˜ì„¸ìš”.")
    st.stop()

df["dt"] = pd.to_datetime(df["timestamp"], errors="coerce")
df["date"] = df["dt"].dt.date
df["rubric_total"] = pd.to_numeric(df["rubric_total"], errors="coerce")
df["guess_correct_num"] = pd.to_numeric(df["guess_correct"], errors="coerce")

# í•„í„°
fltL, fltM, fltR = st.columns([2,2,3])
with fltL:
    max_day = df["date"].max()
    min_day = df["date"].min()
    default_start = max(min_day, (max_day or date.today()) - timedelta(days=14))
    start_day = st.date_input("ì‹œì‘ì¼", value=default_start,
                              min_value=min_day, max_value=max_day or date.today())
with fltM:
    end_day = st.date_input("ì¢…ë£Œì¼", value=max_day or date.today(),
                            min_value=min_day, max_value=max_day or date.today())
with fltR:
    class_options = ["4-ì‚¬ë‘","4-ê¸°ì¨","4-ë³´ëŒ","4-í–‰ë³µ","ê¸°íƒ€"]
    sel_classes = st.multiselect("í•™ê¸‰(ë³µìˆ˜ ì„ íƒ)", class_options, default=class_options)

if start_day > end_day:
    st.error("ì‹œì‘ì¼ì´ ì¢…ë£Œì¼ë³´ë‹¤ ëŠ¦ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."); st.stop()

mask = (df["date"] >= start_day) & (df["date"] <= end_day) & (df["class"].isin(sel_classes))
fdf = df.loc[mask].copy()
if fdf.empty:
    st.info("ì„ íƒí•œ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ì œì¶œì´ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ì¡°ì •í•´ ì£¼ì„¸ìš”.")
    st.stop()

# KPI
K1, K2, K3, K4 = st.columns(4)
with K1:
    st.metric("ì´ ì œì¶œ", len(fdf))
with K2:
    st.metric("í‰ê·  ìê¸°í‰ê°€ ì´ì ", round(fdf["rubric_total"].dropna().astype(int).mean(), 2))
with K3:
    if fdf["guess_correct_num"].notna().any():
        st.metric("ì „ì²´ ì •ë‹µë¥ (í•„í„° ë²”ìœ„)", f"{(fdf['guess_correct_num'].fillna(0).astype(int).mean()*100):.0f}%")
    else:
        st.metric("ì „ì²´ ì •ë‹µë¥ (í•„í„° ë²”ìœ„)", "â€”")
with K4:
    st.metric("ìµœê·¼ ì œì¶œ ì‹œê°", str(fdf.sort_values("dt").iloc[-1]["timestamp"]))

# ìµœê·¼ ì œì¶œ & í•™ê¸‰ë³„ ì œì¶œ í‘œ
T1, T2 = st.columns([2.1, 2.9])
with T1:
    st.write("### í•™ê¸‰ë³„ ì œì¶œ")
    st.dataframe(fdf["class"].value_counts().rename_axis("í•™ê¸‰").reset_index(name="ì œì¶œ ìˆ˜"),
                 use_container_width=True, height=260)
with T2:
    st.write("### ìµœê·¼ ì œì¶œ 10ê±´")
    temp = fdf.copy()
    temp["ì •ë‹µ ìœ í˜•"] = temp["guess_mode"].map({"add":"í•©","sub":"ì°¨"}).fillna("-")
    temp["ì •ë‹µì—¬ë¶€"] = temp["guess_correct_num"].map({1:"ì •ë‹µ",0:"ì˜¤ë‹µ"}).fillna("-")
    cols_show = ["timestamp","class","nickname","quest","ì •ë‹µ ìœ í˜•","guess_value","ì •ë‹µì—¬ë¶€","correct_answer","rubric_total"]
    cols_show = [c for c in cols_show if c in temp.columns]
    st.dataframe(
        temp[cols_show].sort_values("timestamp", ascending=False).head(10),
        use_container_width=True, height=260
    )

st.divider()
st.write("### ì‹œê°í™” & í…ìŠ¤íŠ¸ ë¶„ì„(íƒ­)")

# ===== ì°¨íŠ¸ìš© ë°ì´í„° =====
correct_counts = fdf["guess_correct_num"].map({1:"ì •ë‹µ",0:"ì˜¤ë‹µ"}).value_counts().rename_axis("ì •ë‹µì—¬ë¶€").reset_index(name="ëª…")
hist = (fdf["rubric_total"].dropna().astype(int)
        .value_counts().sort_index().rename_axis("ì´ì (0â€“6)").reset_index(name="ëª…"))
by_class_acc = (fdf.groupby("class")["guess_correct_num"].mean().mul(100).round(1)
                .rename("ì •ë‹µë¥ (%)").reset_index())
by_class_cnt = fdf["class"].value_counts().rename_axis("í•™ê¸‰").reset_index(name="ì œì¶œ ìˆ˜")
by_day = (fdf.groupby("date").size().rename("ì œì¶œ ìˆ˜").reset_index().sort_values("date"))

# ===== ììœ ì‘ë‹µ(quest) í‚¤ì›Œë“œ ì²˜ë¦¬ =====
def tokenize_korean_en(s: str):
    """
    í•œê¸€/ì˜ë¬¸/ìˆ«ìë¥¼ ë‹¨ì–´ë¡œ ì¶”ì¶œ. í•œê¸€ì€ 2ê¸€ì ì´ìƒ, ì˜ë¬¸/ìˆ«ìëŠ” 2ì ì´ìƒë§Œ ì¹´ìš´íŠ¸.
    """
    if not isinstance(s, str):
        return []
    # í•œê¸€, ì˜ë¬¸, ìˆ«ì ë¸”ë¡ ì¶”ì¶œ
    tokens = re.findall(r"[ê°€-í£]{2,}|[A-Za-z0-9]{2,}", s)
    return [t for t in tokens if t.strip()]

stop_default = "ì—ì„œ\nê·¸ë¦¬ê³ \nê·¸ëŸ¬ë©´\ní•˜ì§€ë§Œ\në•Œë¬¸ì—\në‹¤ì‹œ\në˜ëŠ”\nê·¸ë¦¬ê³ \nì…ë‹ˆë‹¤\nì˜ˆë¥¼\nì˜ˆ:".split("\n")
with st.expander("ğŸ” ììœ ì‘ë‹µ(ë¬¸í•­ ìš”ì•½) í‚¤ì›Œë“œ ë¶„ì„ ì„¤ì •", expanded=False):
    st.caption("ë¶ˆìš©ì–´ë¥¼ ì¤„ë°”ê¿ˆìœ¼ë¡œ ì…ë ¥í•˜ì„¸ìš”. (ì„ íƒ)")
    stop_user = st.text_area("ë¶ˆìš©ì–´ ëª©ë¡(ì„ íƒ, ì¤„ë°”ê¿ˆ êµ¬ë¶„)", value="\n".join(stop_default))
    stopwords = set([w.strip() for w in stop_user.splitlines() if w.strip()])

from collections import Counter
texts = fdf["quest"].dropna().astype(str).tolist()
counter = Counter()
for line in texts:
    for tok in tokenize_korean_en(line):
        if tok not in stopwords:
            counter[tok] += 1
kw_df = pd.DataFrame(counter.most_common(30), columns=["ë‹¨ì–´","ë¹ˆë„"]) if counter else pd.DataFrame(columns=["ë‹¨ì–´","ë¹ˆë„"])

# ===== íƒ­(ìš”ì²­ ìˆœì„œ + í‚¤ì›Œë“œ) =====
tabs = st.tabs(["ì •ë‹µì—¬ë¶€ ë¹„ìœ¨", "ìê¸°í‰ê°€ ì´ì  ë¶„í¬", "í•™ê¸‰ë³„ ì •ë‹µë¥ ", "í•™ê¸‰ë³„ ì œì¶œ ìˆ˜", "ë‚ ì§œë³„ ì œì¶œ ì¶”ì´", "ììœ ì‘ë‹µ í‚¤ì›Œë“œ"])

# 1) ì •ë‹µì—¬ë¶€ ë¹„ìœ¨
with tabs[0]:
    if correct_counts.empty:
        st.info("ì •ë‹µ/ì˜¤ë‹µ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    else:
        if altair_available():
            import altair as alt
            chart = alt.Chart(correct_counts).mark_arc(innerRadius=50).encode(
                theta="ëª…:Q",
                color=alt.Color("ì •ë‹µì—¬ë¶€:N", scale=alt.Scale(scheme="tableau10")),
                tooltip=["ì •ë‹µì—¬ë¶€","ëª…"]
            ).properties(height=360)
            st.altair_chart(chart, use_container_width=True)
        else:
            st.bar_chart(correct_counts.set_index("ì •ë‹µì—¬ë¶€"))

# 2) ìê¸°í‰ê°€ ì´ì  ë¶„í¬
with tabs[1]:
    if hist.empty:
        st.info("ì´ì  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        if altair_available():
            import altair as alt
            chart = alt.Chart(hist).mark_bar().encode(
                x=alt.X("ì´ì (0â€“6):O", title="ìê¸°í‰ê°€ ì´ì (0â€“6)"),
                y=alt.Y("ëª…:Q", title="í•™ìƒ ìˆ˜"),
                tooltip=["ì´ì (0â€“6)","ëª…"]
            ).properties(height=360)
            st.altair_chart(chart, use_container_width=True)
        else:
            st.bar_chart(hist.set_index("ì´ì (0â€“6)"))

# 3) í•™ê¸‰ë³„ ì •ë‹µë¥ 
with tabs[2]:
    if by_class_acc.empty:
        st.info("í•™ê¸‰ë³„ ì •ë‹µë¥  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        if altair_available():
            import altair as alt
            chart = alt.Chart(by_class_acc).mark_bar().encode(
                x=alt.X("class:N", title="í•™ê¸‰", sort="-y"),
                y=alt.Y("ì •ë‹µë¥ (%):Q"),
                tooltip=["class","ì •ë‹µë¥ (%)"]
            ).properties(height=360)
            st.altair_chart(chart, use_container_width=True)
        else:
            # ì»¬ëŸ¼ëª… í•œêµ­ì–´ë¡œ ë°”ê¾¸ì§€ ì•Šê³  index ê¸°ë°˜ìœ¼ë¡œë„ í‘œì‹œ ê°€ëŠ¥
            st.bar_chart(by_class_acc.set_index("class"))

# 4) í•™ê¸‰ë³„ ì œì¶œ ìˆ˜
with tabs[3]:
    if by_class_cnt.empty:
        st.info("í•™ê¸‰ë³„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        if altair_available():
            import altair as alt
            chart = alt.Chart(by_class_cnt).mark_bar().encode(
                y=alt.Y("í•™ê¸‰:N", sort="-x"),
                x=alt.X("ì œì¶œ ìˆ˜:Q"),
                tooltip=["í•™ê¸‰","ì œì¶œ ìˆ˜"]
            ).properties(height=360)
            st.altair_chart(chart, use_container_width=True)
        else:
            st.bar_chart(by_class_cnt.set_index("í•™ê¸‰"))

# 5) ë‚ ì§œë³„ ì œì¶œ ì¶”ì´
with tabs[4]:
    if by_day.empty:
        st.info("ë‚ ì§œë³„ ì œì¶œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        if altair_available():
            import altair as alt
            chart = alt.Chart(by_day).mark_line(point=True).encode(
                x=alt.X("date:T", title="ë‚ ì§œ"),
                y=alt.Y("ì œì¶œ ìˆ˜:Q"),
                tooltip=["date:T","ì œì¶œ ìˆ˜:Q"]
            ).properties(height=360)
            st.altair_chart(chart, use_container_width=True)
        else:
            st.line_chart(by_day.set_index("date"))

# 6) ììœ ì‘ë‹µ í‚¤ì›Œë“œ
with tabs[5]:
    st.write("**ë¬¸í•­ ìš”ì•½(quest)ì—ì„œ ë§ì´ ë“±ì¥í•œ ë‹¨ì–´ TOP 30**")
    if kw_df.empty:
        st.info("ììœ ì‘ë‹µ ë°ì´í„°ê°€ ì—†ê±°ë‚˜, ìœ íš¨í•œ ë‹¨ì–´ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        ckw1, ckw2 = st.columns([2,3])
        with ckw1:
            st.dataframe(kw_df, use_container_width=True, height=360)
        with ckw2:
            if altair_available():
                import altair as alt
                chart = alt.Chart(kw_df).mark_bar().encode(
                    y=alt.Y("ë‹¨ì–´:N", sort="-x"),
                    x=alt.X("ë¹ˆë„:Q"),
                    tooltip=["ë‹¨ì–´","ë¹ˆë„"]
                ).properties(height=360)
                st.altair_chart(chart, use_container_width=True)
            else:
                st.bar_chart(kw_df.set_index("ë‹¨ì–´"))

st.divider()
csv = fdf.drop(columns=["dt"]).to_csv(index=False).encode("utf-8-sig")
st.download_button("CSV ë‹¤ìš´ë¡œë“œ(í•„í„° ì ìš©)", csv, file_name="submissions_filtered.csv", mime="text/csv")













